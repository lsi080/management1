import streamlit as st
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# nltk λ°μ΄ν„° λ‹¤μ΄λ΅λ“ (μµμ΄ 1νλ§ μ‹¤ν–‰λ¨)
nltk.download('punkt')
nltk.download('stopwords')

st.set_page_config(page_title="NoteSyncer Demo", layout="centered")
st.title("π“ NoteSyncer - λ…ΈνΈ μ •λ¦¬ μ•± (Streamlit μ „μ© λ°λ¨)")
st.markdown("ν•™μƒλ“¤μ„ μ„ν• **λ…ΈνΈ μ”μ•½ μ •λ¦¬ λ„μ°λ―Έ**μ…λ‹λ‹¤. μ‚¬μ§„μ΄ μ—†μ–΄λ„ ν…μ¤νΈλ΅ μ§μ ‘ μ…λ ¥ν•΄ μ—°μµν•  μ μμ–΄μ”.")

st.subheader("1οΈβƒ£ λ…ΈνΈ λ‚΄μ© μ…λ ¥")
text_input = st.text_area("λ…ΈνΈ μ‚¬μ§„μ—μ„ λ³µμ‚¬ν• λ‚΄μ©μ΄λ‚ μ§μ ‘ μ…λ ¥ν• ν•„κΈ°λ¥Ό μ—¬κΈ°μ— λ¶™μ—¬λ„£μΌμ„Έμ”:", height=200)

if text_input.strip() != "":
    st.subheader("2οΈβƒ£ μλ™ ν‚¤μ›λ“ μ”μ•½")

    lang = st.radio("μ–Έμ–΄ μ„ νƒ", ['ν•κΈ€', 'μμ–΄'])

    if lang == 'μμ–΄':
        words = word_tokenize(text_input)
        stop_words = set(stopwords.words('english'))
        filtered_words = [w for w in words if w.isalpha() and w.lower() not in stop_words]
    else:
        filtered_words = [word for word in text_input.split() if len(word) >= 2 and word.isalpha()]

    freq = {}
    for word in filtered_words:
        freq[word] = freq.get(word, 0) + 1

    sorted_keywords = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:5]

    if sorted_keywords:
        for word, count in sorted_keywords:
            st.markdown(f"- **{word}** ({count}ν λ“±μ¥)")
        st.success("π‰ μ”μ•½ μ™„λ£! μ΄ ν‚¤μ›λ“λ¥Ό μ¤‘μ‹¬μΌλ΅ λ³µμµν•΄λ³΄μ„Έμ”.")
    else:
        st.warning("μ μλ―Έν• ν‚¤μ›λ“λ¥Ό μ°Ύμ§€ λ»ν–μ–΄μ”. μ…λ ¥μ„ ν™•μΈν•΄λ³΄μ„Έμ”.")

else:
    st.info("λ…ΈνΈ λ‚΄μ©μ„ μ…λ ¥ν•λ©΄ μλ™μΌλ΅ ν‚¤μ›λ“λ¥Ό μ¶”μ¶ν•΄λ“λ¦½λ‹λ‹¤.")
